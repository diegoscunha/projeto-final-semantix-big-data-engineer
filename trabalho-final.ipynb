{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final de Spark\n",
    "\n",
    "*Diego Silva Cunha*\n",
    "\n",
    "**Nível Básico:**\n",
    "\n",
    "Dados: https://mobileapps.saude.gov.br/esus-vepi/files/unAFkcaNDeXajurGB7LChj8SgQYS2ptm/04bd3419b22b9cc5c6efac2c6528100d_HIST_PAINEL_COVIDBR_06jul2021.rar\n",
    "\n",
    "Referência das Visualizações:\n",
    "* Site: https://covid.saude.gov.br/\n",
    "* Guia do Site: Painel Geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Enviar os dados para o hdfs**\n",
    "\n",
    "Salvei os arquivos dentro da pasta /input/dados e faço o envio dos arquivos para o HDFS onde será mapeada a tabela Hive 'painel_covid_temp'.\n",
    "```\n",
    "hdfs dfs -put /input/dados /user/diego/trabalho-final/data/painel_covid_temp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Otimizar todos os dados do hdfs para uma tabela Hive particionada por município.**\n",
    "\n",
    "Conectar ao Hive com o comando abaixo:\n",
    "```\n",
    "beeline -u jdbc:hive2://localhost:10000\n",
    "```\n",
    "Criando o banco de dados Hive\n",
    "```\n",
    "create database trabalhofinal;\n",
    "use trabalhofinal;\n",
    "```\n",
    "Criando tabela Hive 'painel_covid_temp'\n",
    "```\n",
    "create external table painel_covid_temp (\n",
    "    regiao string,\n",
    "    estado string,\n",
    "    municipio string,\n",
    "    coduf int,\n",
    "    codmun int,\n",
    "    codRegiaoSaude int,\n",
    "    nomeRegiaoSaude string,\n",
    "    data date,\n",
    "    semanaEpi int,\n",
    "    populacaoTCU2019 int,\n",
    "    casosAcumulado int,\n",
    "    casosNovos int,\n",
    "    obitosAcumulado int,\n",
    "    obitosNovos int,\n",
    "    Recuperadosnovos int,\n",
    "    emAcompanhamentoNovos int,\n",
    "    interior_metropolitana int\n",
    ")\n",
    "row format delimited\n",
    "fields terminated by ';'\n",
    "location'/user/diego/trabalho-final/data/painel_covid_temp'\n",
    "tblproperties(\"skip.header.line.count\"=\"1\");\n",
    "```\n",
    "Realizando a configuração do Hive para suportar particionamento dinâmico.\n",
    "```\n",
    "SET hive.exec.dynamic.partition = true;\n",
    "SET hive.exec.dynamic.partition.mode = nonstrict;\n",
    "```\n",
    "Criando a tabela 'painel_covid' particionada por regiões do Brasil.\n",
    "```\n",
    "create table painel_covid (\n",
    "    estado string,\n",
    "    municipio string,\n",
    "    coduf int,\n",
    "    codmun int,\n",
    "    codRegiaoSaude int,\n",
    "    nomeRegiaoSaude string,\n",
    "    data date,\n",
    "    semanaEpi int,\n",
    "    populacaoTCU2019 int,\n",
    "    casosAcumulado int,\n",
    "    casosNovos int,\n",
    "    obitosAcumulado int,\n",
    "    obitosNovos int,\n",
    "    Recuperadosnovos int,\n",
    "    emAcompanhamentoNovos int,\n",
    "    interior_metropolitana int\n",
    ")\n",
    "partitioned by (regiao string);\n",
    "```\n",
    "Carregando os dados da tabela 'painel_covid_temp' para a tabela particionada por região 'painel_covid'.\n",
    "```\n",
    "insert overwrite table painel_covid partition(regiao) select estado,municipio,coduf,codmun,codRegiaoSaude,nomeRegiaoSaude,data,semanaEpi,populacaoTCU2019,casosAcumulado,casosNovos,obitosAcumulado,obitosNovos,Recuperadosnovos,emAcompanhamentoNovos,interior_metropolitana,regiao from painel_covid_temp;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def calcular_incidencia(casos, populacao, por_habitantes):\n",
    "    return (casos * por_habitantes) / populacao\n",
    "\n",
    "def calcular_mortalidade(obitos, populacao, por_habitantes):\n",
    "    return (obitos * por_habitantes) / populacao\n",
    "\n",
    "def calcular_letalidade(obitos, casos):\n",
    "    return (obitos * 100) / casos\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "spark.catalog.setCurrentDatabase(dbName=\"trabalhofinal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Criar as 3 vizualizações pelo Spark com os dados enviados para o HDFS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel_covid = spark.read.table(\"painel_covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualização 1 - Casos recuperados e em acompahamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+\n",
      "|recuperadosnovos|emacompanhamentonovos|\n",
      "+----------------+---------------------+\n",
      "|        17262646|              1317658|\n",
      "+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vizualizacao_1 = painel_covid.select(\"recuperadosnovos\",\"emacompanhamentonovos\")\\\n",
    "            .agg({\"recuperadosnovos\": \"max\", \"emacompanhamentonovos\": \"max\"})\\\n",
    "            .withColumnRenamed(\"max(recuperadosnovos)\",\"recuperadosnovos\")\\\n",
    "            .withColumnRenamed(\"max(emacompanhamentonovos)\",\"emacompanhamentonovos\")\n",
    "vizualizacao_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualização 2 - Casos confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+-----------------+\n",
      "|populacaoTCU2019|casosacumulado|casosnovos|      incidencia*|\n",
      "+----------------+--------------+----------+-----------------+\n",
      "|       210147125|      18855015|    115228|89722.93068467462|\n",
      "+----------------+--------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vizualizacao_2 = painel_covid.select(\"casosacumulado\",\"casosnovos\",\"populacaoTCU2019\")\\\n",
    "            .agg({\"casosacumulado\":\"max\",\"casosnovos\":\"max\",\"populacaoTCU2019\":\"max\"})\\\n",
    "            .withColumnRenamed(\"max(casosacumulado)\",\"casosacumulado\")\\\n",
    "            .withColumnRenamed(\"max(casosnovos)\",\"casosnovos\")\\\n",
    "            .withColumnRenamed(\"max(populacaoTCU2019)\",\"populacaoTCU2019\")\\\n",
    "            .withColumn(\"incidencia*\", calcular_incidencia(col(\"casosacumulado\").cast(FloatType()), col(\"populacaoTCU2019\").cast(FloatType()),1000000))\n",
    "vizualizacao_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualização 3 - Óbitos confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+---------------+--------------+-----------------+------------------+\n",
      "|populacaoTCU2019|obitosnovos|obitosacumulado|casosacumulado|       letalidade|       mortalidade|\n",
      "+----------------+-----------+---------------+--------------+-----------------+------------------+\n",
      "|       210147125|       4249|         526892|      18855015|2.794439421318974|2507.2530493113586|\n",
      "+----------------+-----------+---------------+--------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vizualizacao_3 = painel_covid.select(\"casosacumulado\",\"obitosacumulado\",\"obitosnovos\",\"populacaoTCU2019\")\\\n",
    "            .agg({\"casosacumulado\":\"max\",\"obitosacumulado\":\"max\",\"obitosnovos\":\"max\",\"populacaoTCU2019\":\"max\"})\\\n",
    "            .withColumnRenamed(\"max(casosacumulado)\",\"casosacumulado\")\\\n",
    "            .withColumnRenamed(\"max(obitosacumulado)\",\"obitosacumulado\")\\\n",
    "            .withColumnRenamed(\"max(obitosnovos)\",\"obitosnovos\")\\\n",
    "            .withColumnRenamed(\"max(populacaoTCU2019)\",\"populacaoTCU2019\")\\\n",
    "            .withColumn(\"letalidade\", calcular_letalidade(col(\"obitosacumulado\").cast(FloatType()), col(\"casosacumulado\").cast(FloatType())))\\\n",
    "            .withColumn(\"mortalidade\", calcular_mortalidade(col(\"obitosacumulado\").cast(FloatType()), col(\"populacaoTCU2019\").cast(FloatType()),1000000))\n",
    "vizualizacao_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Salvar a primeira visualização como tabela Hive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualizacao_1.write.saveAsTable(\"trabalhofinal.v1_casos_recuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Salvar a segunda visualização com formato parquet e compressão snappy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualizacao_2.write.option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(\"/user/diego/trabalho-final/data/v2_casos_confirmados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Salvar a terceira visualização em um tópico no Kafka**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualizacao_3.selectExpr(\"CONCAT(1) AS value\", \"CAST(obitosacumulado AS STRING)\",\"CAST(obitosnovos AS STRING)\",\"CAST(letalidade AS STRING)\",\"CAST(mortalidade AS STRING)\")\\\n",
    "            .write\\\n",
    "            .format(\"kafka\")\\\n",
    "            .option(\"kafka.bootstrap.servers\",\"kafka:9092\")\\\n",
    "            .option(\"topic\",\"v3-obitos-confirmados\")\\\n",
    "            .option(\"value\", \"1\")\\\n",
    "            .option(\"checkpointLocation\",\"/user/diego/trabalho-final/data/kafka/checkpoint\")\\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Criar a visualização pelo Spark com os dados enviados para o HDFS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------------+--------------+------------------+------------------+\n",
      "|      regiao|populacaoTCU2019|obitosacumulado|casosacumulado|  incidencia100mil| mortalidade100mil|\n",
      "+------------+----------------+---------------+--------------+------------------+------------------+\n",
      "|    Nordeste|         2872347|         115502|       4426773|154116.92847417112|4021.1714698815986|\n",
      "|         Sul|         1933105|          85038|       3780833|195583.43267230698|4399.0366834703755|\n",
      "|     Sudeste|        12252023|         244856|       7129027|58186.530106252656|1998.4943900284875|\n",
      "|Centro-Oeste|         3015268|          49490|       1916634|63564.302444757814|1641.3135389623742|\n",
      "|      Brasil|       210147125|         526892|      18855015| 8972.293567439801|250.72529713469308|\n",
      "|       Norte|         2182763|          43929|       1730152| 79264.31034427467|2012.5410298781865|\n",
      "+------------+----------------+---------------+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vizualizacao_regioes = painel_covid.where((col(\"municipio\")!=\"\") | (col(\"regiao\")==\"Brasil\"))\\\n",
    "            .groupBy(\"regiao\",\"municipio\").agg({\"casosacumulado\":\"max\",\"obitosacumulado\":\"max\",\"populacaoTCU2019\":\"max\"})\\\n",
    "            .withColumnRenamed(\"max(casosacumulado)\",\"casosacumulado\")\\\n",
    "            .withColumnRenamed(\"max(obitosacumulado)\",\"obitosacumulado\")\\\n",
    "            .withColumnRenamed(\"max(populacaoTCU2019)\",\"populacaoTCU2019\")\\\n",
    "            .groupBy(\"regiao\").agg({\"casosacumulado\":\"sum\",\"obitosacumulado\":\"sum\",\"populacaoTCU2019\":\"max\"})\\\n",
    "            .withColumnRenamed(\"sum(casosacumulado)\",\"casosacumulado\")\\\n",
    "            .withColumnRenamed(\"sum(obitosacumulado)\",\"obitosacumulado\")\\\n",
    "            .withColumnRenamed(\"max(populacaoTCU2019)\",\"populacaoTCU2019\")\\\n",
    "            .withColumn(\"incidencia100mil\", calcular_incidencia100mil(col(\"casosacumulado\").cast(FloatType()), col(\"populacaoTCU2019\").cast(FloatType()),100000))\\\n",
    "            .withColumn(\"mortalidade100mil\", calcular_mortalidade100mil(col(\"obitosacumulado\").cast(FloatType()), col(\"populacaoTCU2019\").cast(FloatType()),100000))\n",
    "vizualizacao_regioes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Salvar a visualização do exercício 6 em um tópico no Elastic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Criar um dashboard no Elastic para visualização dos novos dados enviados**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
